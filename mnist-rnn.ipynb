{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST Sequential Neural Network\n",
    "\n",
    "Use como guía el código siguiente y desarrolle\n",
    "\n",
    "1.1 Una red densa para clasificacion binaria entre los dígitos 4 y 9 con al menos igual desempeño que la red densa del código de ejemplo.\n",
    "\n",
    "1.2 Una red convolucional para clasificar los dígitos 4 y 9 con al menos igual desempeño que la red densa del punto 1.1.\n",
    "\n",
    "1.3 Compare la degradación del desempeño entre los diseños de los punto 1.1 y el 1.2 cuando se agrega ruido Gaussiano a las imágenes. Esto es, fijando la arquitectura, reenetrenelas para al menos 5 niveles de ruido distintos y gráfique su presicion. Use la desviación estandar como razón del rango dinámicos de las imágenes, $\\sigma = 0.0,  0.2, 0.4, 0.6,$ y $0.8$.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images  = test_images.reshape((10000, 28 * 28))\n",
    "test_images  = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels  = to_categorical(test_labels)\n",
    "numIm, szIm  = train_images.shape\n",
    "\n",
    "nn = models.Sequential()    \n",
    "nn.add(layers.Dense(units=10,activation='relu', input_shape=(szIm,)))         \n",
    "nn.add(layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "nn.compile(optimizer='rmsprop',loss ='categorical_crossentropy',metrics  =['accuracy'])\n",
    "\n",
    "nn.fit(x = train_images, y = train_labels, validation_split=0.2,\n",
    "                 epochs = 10, shuffle = True, batch_size = 128)\n",
    "\n",
    "results = nn.evaluate(test_images, test_labels)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('accuray: {}%'.format(results[1]*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.8357 - acc: 0.7823 - val_loss: 0.4137 - val_acc: 0.8921\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.3773 - acc: 0.8957 - val_loss: 0.3236 - val_acc: 0.9095\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 3s 69us/step - loss: 0.3219 - acc: 0.9092 - val_loss: 0.2920 - val_acc: 0.9181\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 4s 78us/step - loss: 0.2978 - acc: 0.9161 - val_loss: 0.2765 - val_acc: 0.9206\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.2823 - acc: 0.9199 - val_loss: 0.2658 - val_acc: 0.9252\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.2722 - acc: 0.9230 - val_loss: 0.2576 - val_acc: 0.9283\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 3s 72us/step - loss: 0.2637 - acc: 0.9258 - val_loss: 0.2625 - val_acc: 0.9249\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 4s 75us/step - loss: 0.2579 - acc: 0.9274 - val_loss: 0.2509 - val_acc: 0.9297\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 4s 77us/step - loss: 0.2524 - acc: 0.9286 - val_loss: 0.2487 - val_acc: 0.9312\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.2477 - acc: 0.9295 - val_loss: 0.2467 - val_acc: 0.9319\n",
      "10000/10000 [==============================] - 1s 80us/step\n",
      "loss:  0.2550721585392952\n",
      "accuray: 92.83%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Respuestas\n",
    "\n",
    "### Respuesta a 1.1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def sample_data(X, y, samples, d1=4, d2=9):\n",
    "    y1 = y[:,d1]\n",
    "    y1 = y1.astype(bool)\n",
    "    y2 = y[:,d2]\n",
    "    y2 = y2.astype(bool)\n",
    "    \n",
    "    X1 = X[y1]\n",
    "    X2 = X[y2]\n",
    "    X1 = X1[:samples]\n",
    "    X2 = X2[:samples]\n",
    "    X_sample = np.r_[X1, X2]\n",
    "    \n",
    "    y1 = np.zeros(samples)\n",
    "    y2 = np.ones(samples)\n",
    "    \n",
    "    y_sample = np.r_[y1, y2]\n",
    "    y_sample = to_categorical(y_sample)\n",
    "    return X_sample, y_sample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "print(train_images.shape)\n",
    "X_train, y_train = sample_data(train_images, train_labels, 2000, d1=4, d2=9) #Muestreamos los digitos 4 y 9\n",
    "X_test, y_test = sample_data(test_images, test_labels, 900, d1=4, d2=9) #Muestreamos los digitos 4 y 9\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000, 784)\n",
      "(4000, 784)\n",
      "(4000, 2)\n",
      "(1800, 784)\n",
      "(1800, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "def dense_net(X_train, y_train, X_test, y_test, verbose=1):\n",
    "    network = models.Sequential()    \n",
    "    network.add(layers.Dense(units=32, activation='relu', input_shape=(szIm,)))\n",
    "    network.add(layers.Dropout(0.5))\n",
    "    network.add(layers.Dense(units=64,activation='relu'))\n",
    "    network.add(layers.Dense(units=2, activation='softmax'))\n",
    "\n",
    "    network.compile(optimizer='rmsprop',loss ='categorical_crossentropy',metrics  =['accuracy'])\n",
    "\n",
    "    network.fit(x = X_train, y = y_train, validation_split=0.2, epochs = 10, shuffle = True, batch_size = 128,verbose=verbose)\n",
    "\n",
    "    results = network.evaluate(X_test, y_test)\n",
    "\n",
    "    print('loss: ', results[0])\n",
    "    print('accuray: {}%'.format(results[1]*100))\n",
    "    return results[1]*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "dense_net(X_train, y_train, X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 2s 543us/step - loss: 0.4607 - acc: 0.7891 - val_loss: 0.5084 - val_acc: 0.8100\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 0s 73us/step - loss: 0.2306 - acc: 0.9184 - val_loss: 0.3305 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 0s 82us/step - loss: 0.1590 - acc: 0.9462 - val_loss: 0.1941 - val_acc: 0.9400\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 0s 92us/step - loss: 0.1231 - acc: 0.9625 - val_loss: 0.1438 - val_acc: 0.9600\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 0s 92us/step - loss: 0.1138 - acc: 0.9594 - val_loss: 0.1616 - val_acc: 0.9550\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 0s 86us/step - loss: 0.0947 - acc: 0.9691 - val_loss: 0.1918 - val_acc: 0.9450\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 0s 84us/step - loss: 0.0876 - acc: 0.9731 - val_loss: 0.2915 - val_acc: 0.9187\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 0s 99us/step - loss: 0.0755 - acc: 0.9753 - val_loss: 0.1583 - val_acc: 0.9613\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 0s 93us/step - loss: 0.0748 - acc: 0.9744 - val_loss: 0.2023 - val_acc: 0.9437\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 0s 96us/step - loss: 0.0596 - acc: 0.9784 - val_loss: 0.2721 - val_acc: 0.9287\n",
      "1800/1800 [==============================] - 0s 136us/step\n",
      "loss:  0.11120782630084755\n",
      "accuray: 96.22222222222221%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "96.22222222222221"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Respuesta a 1.2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "#Trasnformación de Matriz tensor de imagenes\n",
    "X1_train = X_train.reshape(2000*2, 28, 28, 1)\n",
    "X2_test = X_test.reshape(900*2, 28, 28, 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "def cov_net(X_train, y_train, X_test, y_test, verbose=1):\n",
    "    network1 = models.Sequential()\n",
    "    network1.add(layers.Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(28, 28,1)))\n",
    "    network1.add(layers.MaxPooling2D((2, 2)))\n",
    "    network1.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    network1.add(layers.MaxPooling2D((2, 2)))\n",
    "    network1.add(layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "    network1.add(layers.Flatten())\n",
    "    network1.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "    network1.compile(optimizer='rmsprop',loss ='categorical_crossentropy',metrics  =['accuracy'])\n",
    "\n",
    "    network1.fit(x = X_train, y = y_train, validation_split=0.2, epochs = 10, shuffle = True, batch_size = 128, verbose=verbose)\n",
    "\n",
    "    results = network1.evaluate(X_test, y_test)\n",
    "\n",
    "    print('loss: ', results[0])\n",
    "    print('accuray: {}%'.format(results[1]*100))\n",
    "    return results[1]*100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "cov_net(X1_train, y_train, X2_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 4s 1ms/step - loss: 0.3188 - acc: 0.8578 - val_loss: 0.0209 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 2s 687us/step - loss: 0.0592 - acc: 0.9834 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 2s 712us/step - loss: 0.0322 - acc: 0.9888 - val_loss: 0.0526 - val_acc: 0.9800\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 2s 713us/step - loss: 0.0238 - acc: 0.9922 - val_loss: 0.0235 - val_acc: 0.9900\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 2s 714us/step - loss: 0.0218 - acc: 0.9925 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 2s 718us/step - loss: 0.0154 - acc: 0.9956 - val_loss: 0.0228 - val_acc: 0.9938\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 2s 716us/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0073 - val_acc: 0.9975\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 2s 717us/step - loss: 0.0111 - acc: 0.9959 - val_loss: 0.0062 - val_acc: 0.9975\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 2s 692us/step - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0255 - val_acc: 0.9900\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 2s 723us/step - loss: 0.0044 - acc: 0.9991 - val_loss: 0.0107 - val_acc: 0.9962\n",
      "1800/1800 [==============================] - 0s 205us/step\n",
      "loss:  0.012819020398211351\n",
      "accuray: 99.55555555555556%\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "99.55555555555556"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Respuesta a 1.3"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "def comparison(sigma=[0.0,0.2,0.4,0.6,0.8], verbose=0):\n",
    "    den, cov = [],[]\n",
    "    for s in sigma:\n",
    "        den.append(dense_net(X_train + np.random.normal(scale=s, size=(4000,784)), y_train, X_test, y_test, verbose))\n",
    "        cov.append(cov_net(X1_train + np.random.normal(scale=s, size=(4000,28,28,1)), y_train, X2_test, y_test, verbose))\n",
    "        \n",
    "    plt.plot(sigma, den)\n",
    "    plt.plot(sigma, cov)\n",
    "    plt.legend([\"densa\", \"covnet\"])\n",
    "    plt.xlabel(\"$\\sigma$ (ruido gauss)\")\n",
    "    plt.ylabel(\"$test acc$ (desempeño)\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "comparison()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1800/1800 [==============================] - 0s 160us/step\n",
      "loss:  0.07734487788894007\n",
      "accuray: 97.16666666666667%\n",
      "1800/1800 [==============================] - 0s 227us/step\n",
      "loss:  0.01213952445662244\n",
      "accuray: 99.66666666666667%\n",
      "1800/1800 [==============================] - 0s 131us/step\n",
      "loss:  0.10218497757421574\n",
      "accuray: 96.77777777777777%\n",
      "1800/1800 [==============================] - 0s 274us/step\n",
      "loss:  0.024705001468116102\n",
      "accuray: 99.11111111111111%\n",
      "1800/1800 [==============================] - 0s 106us/step\n",
      "loss:  0.10978065650114634\n",
      "accuray: 95.94444444444444%\n",
      "1800/1800 [==============================] - 0s 243us/step\n",
      "loss:  0.012854142657840333\n",
      "accuray: 99.55555555555556%\n",
      "1800/1800 [==============================] - 0s 141us/step\n",
      "loss:  0.12769417143944237\n",
      "accuray: 95.05555555555556%\n",
      "1800/1800 [==============================] - 0s 222us/step\n",
      "loss:  0.013135800134401103\n",
      "accuray: 99.55555555555556%\n",
      "1800/1800 [==============================] - 0s 136us/step\n",
      "loss:  0.20986101723379558\n",
      "accuray: 93.94444444444444%\n",
      "1800/1800 [==============================] - 0s 224us/step\n",
      "loss:  0.016882010206852177\n",
      "accuray: 99.27777777777777%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEOCAYAAACNY7BQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VPW9//HXJyEQEkIgGwGSEPbVEEgIVdkUFOuCGwjidalWbq0/69Ja25/3ttrWVqtXbe9PW9e2tiII7mtd2FWWhE2WsJMQ9p1ACNk+vz/OCcnEAJkksyT5PB+PPJg558zMJwPMe77L+R5RVYwxxphKIYEuwBhjTHCxYDDGGOPBgsEYY4wHCwZjjDEeLBiMMcZ4sGAwxhjjwYLBGGOMBwsGY4wxHiwYjDHGeGgV6ALqIy4uTlNTUwNdhjHGNCk5OTkHVDX+XMc1yWBITU0lOzs70GUYY0yTIiJ5dTnOupKMMcZ4sGAwxhjjwYLBGGOMBwsGY4wxHiwYjDHGeLBgMMYY48GCwRhjjIcmeR5DvW38NxzYCKkjIDENQkIDXZExxgSdlhUMmz6HZS85t8OjoduFTkikjoROgyDEGlDGGNOyguGKp2DkA7B9EWxfCNsWwoaPnX3hHapCInUEJAywoDDGtEgtKxgA2neBtBucH4CjBZ5Bkfuhs71tDKReCKmj3KDoDyKBq9sYY/yk5QVDTdFJMHiK8wNwJN8Jim0LnbBY/4GzPSLODYqR0H0UxPWxoDCgCsd2wa4VsHslHNwMWhHoqpoOCYXortChG3RIqfppHRnoylo0UdVA1+C1zMxM9csieqpwJM8NCbdVcWynsy8ywe16GuEERWwvC4qW4NjuqhDYtQJ2rYQT+5x9EgodUyE0LKAlNinlJXB0J5Sf8tweEecERMfqgdHN/UmGsLaBqbeJE5EcVc0853EWDF5QhcPbPIOicLezr12iGxIjnVZFTA8LiqaucG+1AHBD4PgeZ5+EQHw/6DIEOqc7fyYOsg+s+qiocML1SL7zc3h71e0j+XB0hxMg1UUm1AiNasERnQRh4QH5VYKdBYM/qMLBLU5AbHfD4vheZ19UFzck3AHtjqkWFMHs+H7PVsCuFVC4y90pEN+3KgAqQ8C6O/yjosIJ5NPBkee05I/kO38eLYCKMs/HRHWuERjVAiQ6GVq1DszvEmAWDIGgCgc2eQbFif3OvvZJNYKiW2BrbclOHITd1QJg10o4VuDuFKdbsDIAuqQ757y0aRfQks1ZVJQ7LffToZFfFRpH8pyuKi2v9gBxJqHUFhodu0H7rs22O9CCIRiowv4NnkFRdNDZ1yHFnRrrhkWH5MDW2lwVHYLdq6q6g3avdD40KsX0rAqALkOcEAhvH7h6TeMrL3Naf98JDff2sZ2eEwYkxAmH2kKjQ4rTGxDaNOftWDAEo4oK2J/rTo1dAHlfwcnDzr6OqW5rwp0eG901oKU2SSePVIVAZbfQ4e1V+zt2rwqAyhBo2yFg5ZogUV7qdEfVFhpH8p1ZZ1T7nAxp5QaH2+KoOdYR1TloV1WwYGgKKipg39qq6bF5i6D4qLMvpodni6J958DWGmyKjzkhUH1w+NDWqv0dunmGQOfB0LZj4Oo1TVfZqWrBUSM0DudVTUioFBLmDIB7tDS6VQVJu04BO3nWgqEpqiiHvWuqZj3lfQ2n3KCI7VUVEqkjIapTYGv1p1OFsHu1Zwgc3Fy1Pzq5KgQqB4gjYgJXr2lZSovd4Nj+3dA4kl81nblSaGvn32ytU3FToF2CzyaqWDA0BxXlsGe1Z1CUFDr74vpWTY/tNgLaxQe21sZScgL2fOs5RfTARk435dt39QyALukQGRfQko05q5IiZ8pt9RZH9fGOogOex7cKrzENt0ZwRMbVOzgsGJqj8jKn+6RyMDvvGyg94eyL718166nbCIiMDWytdVFS5LSQqk8RPbChaiAwqrPnFNEu6c63KWOak5ITNVoa2z3vnzzkefyU6dDvinq9lAVDS1Be6nygVgZF/mIoLXL2JQysOtmu2wWB71opLf5uCOzPrZpGGJngGQCd021cxRhwxtMqWxyH86D/VfWenGLB0BKVlTgfuNsXOF1P+Uug7CQgzglZlYPZ3c737UBs2Sk3BFZWzRDat77qJKSIOM8pol2GOK0DOwHQGJ+yYDDOB/TO5VUtih1LoawYEOic5hkU4dH1fI0S2LfOc4ro3nVQUersbxtTY3ZQujNjw0LAGL+zYDDfVVoMO7OrpscWLHXWoJEQZzpn9aBoE/Xdx5eXOt/8PUJgbdU6NuHRngHQZYgzWGYhYExQsGAw51Z6EgqWVQuKZc43fQl1vuVXrvFUOTawZ03VKphtoqHLYM8QsPWgjAlqFgzGeyVFTiuicnrszmxnXKB1lDsgPLiqRdCxu13hzpgmpq7B4NcFP0TkXuBOQICXVPVZERkM/BVoB2wHblLVY/6sy7haR0CPMc4PONPoju+FDqkWAsa0IH773y4ig3BCIQsYDFwpIr2Bl4FfqOp5wDvAg/6qyZxD60hnaQ4LBWNaFH/+j+8PLFbVIlUtA+YD1wJ9gQXuMZ8D1/uxJmOMMTX4MxjWAKNEJFZEIoDLgWR3+wT3mEnutu8QkWkiki0i2fv37/dLwcYY0xL5LRhUdT3wBE6r4FNgFVAG3A7cLSI5QBRQcobHv6iqmaqaGR/fTNYFMsaYIOTXzmNVfUVVh6rqKOAQsElVc1X1UlXNAN4AtvizJmOMMZ78GgwikuD+mQJcB7xRbVsI8F84M5SMMcYEiL+nm7wlIuuAD4C7VfUwcKOIbARygV3A3/xckzHGmGr8eh6Dqo6sZdufgD/5sw5jjDFnZhPUjTHGeLBgMMYY48GCwRhjjAcLBmOMMR4sGIwxxniwYDDGGOPBgsEYY4wHCwZjjDEeLBiMMcZ4sGAwxhjjwYLBGGOMBwsGY4wxHiwYjDHGeLBgMMYY48GCwRhjjAcLBmOMMR4sGIwxxniwYDDGGOPBgsEYY4wHr4NBRCJFJNQXxRhjjAm8cwaDiISIyFQR+UhE9gG5wG4RWSsiT4pIb9+XaYwxxl/q0mKYC/QEfgkkqmqyqiYAI4HFwOMi8h8+rNEYY4wftarDMeNUtbTmRlU9BLwFvCUiYY1emTHGmIA4ZzBUDwURGYzTUgBYqKqrah5jjDGmaavz4LOI3Au8DiS4P/8SkXt8VZgxxpjA8GZW0h3AcFX9lar+CvgecKc3LyYi94rIGnfg+j53W7qILBaRlSKSLSJZ3jynMcaYxuVNMAhQXu1+ubutbg8WGYQTJFnAYOBKd0bTH4FHVTUd+JV73xhjTIDUZfC50t+AJSLyDk4gXA286sXj+wOLVbUIQETmA9cCCrR3j4kGdnnxnMYYYxpZnYNBVZ8WkXnACHfTD1R1hRevtQZ4TERigZPA5UA2cB/wbxF5CqcFc4EXz2mMMaaReTP43AboB7QDOgBXiciv6vp4VV0PPAF8DnwKrALKgLuA+1U1GbgfeOUMrz/NHYPI3r9/f11f1hhjjJfqcubzT92b7+F0H5UBJ6r91JmqvqKqQ1V1FHAI2ATcCrztHjILZwyitse+qKqZqpoZHx/vzcsaY4zxQl26ksYA/wMkqeplDXkxEUlQ1X0ikgJcB5wP3AOMBuYBF+OEhTHGmACpSzBUDgx/LSLnqeq3DXi9t9wxhlLgblU9LCJ3An8SkVZAMTCtAc9vjDGmgeoSDD90/xwB/EBEtgKncGYmqaqm1fXFVHVkLdsWARl1fQ5jjDG+VZclMSq7dr7v41qMMcYEAW9OcMvHWSfpVlXNwzn/oJNPqjLGGBMw3gTD8ziDxTe69wuB5xq9ImOMMQHlzZnPw1V1qIisAHAHjlv7qC5jjDEB4k2LodS9pKcCiEg8UOGTqowxxgSMN8HwZ+AdoJOIPAYsAn7vk6qMMcYEjDdrJb0uIjnAWHfTNe4yF8YYY5qROgeDiITjLHw3EqcLqbWIbFPVYl8VZ4wxxv+8GXx+DWcm0p/d+zcC/wQmNXZRxhhjAsebYOirqoOr3Z8rIqsauyBjjDGB5c3g8woR+V7lHREZDnzV+CUZY4wJJK/OYwBuEZF8934KsF5EvsXLNZOMMcYEL2+CoUFLbhtjjGkavJmumufLQowxxgQHb6arZgIPA93cx3m97LYxxpjg501X0uvAg8C32FIYxhjTbHkTDPtV9X2fVWKMMSYoeBMMvxaRl4Evca7gBoCqvt3oVRljjAkYb4LhB0A/IIyqriQFLBiMMaYZ8SYYBqvqeT6rxBhjTFDw5sznxSIywGeVGGOMCQretBhGALeKyDacMQabrmqMMc1Qizrzec/RYkIE4qPaICKBLscYY4KSN8GQD9wE9FDV34hICpAINJkzop+ft5nXvsmjY0QYfROj6JfYnn6JUfRNjKJPpygi23jzdhhjTPPkzSfh8zizkS4GfoNzbYa3gGE+qMsnbshMpkdcJBv2FrJ+dyFvZu+gqKT89P6UmAg3MJzQ6JsYRWpsBK1CvRmKMcaYps2r1VVVdaiIrABQ1cMi0tpHdfnEoK7RDOoaffp+RYVScPgkuXuOsWFPIbl7Csndc4wv1++lQp1jWrcKoXdCO/omRtHfDYt+iVHWHWWMaba8CYZSEQnFOXcBEYnHy6UxRORe4E6cgeuXVPVZEZkJ9HUP6QAcUdV0b563vkJChJTYCFJiI7h0YOLp7cWl5Wzed9wNi2Pk7ilk0aYDvL185+ljrDvKGNNcefMp9mfgHSBBRB4DJgL/VdcHi8ggnFDIAkqAT0XkI1WdXO2Y/wGOelGTT4SHhX6ndQFw+ETJ6VZFZQvjTN1R/ROj6GvdUcaYJsibZbdfF5EcYCzON/5rVHW9F6/VH1isqkUAIjIfuBb4o3tfgBtwxjCCUsfI1pzfM5bze8ae3lbZHbXeDYsNZ+mOqt66sO4oY0ywElX1zwuJ9AfeA84HTuKsuZStqve4+0cBT6tq5hkePw2YBpCSkpKRlxfck6Equ6Ny9xSywe2O2rCnkH2Fp5eZsu4oY4xfiUjOmT5jPY6razCIyCTgU1UtFJH/AoYCv1PV5V4UdQdwN3AcWAecVNX73X1/ATar6v+c63kyMzM1Ozu7ri8bVA6dKDndFVXZHbVxb+F3uqP6ua0K644yxjQWXwTDalVNE5ERwB+Ap4D/q6rD61ng74ECVX1eRFoBO4EMVS0412ObcjDUpqJC2XG46HSrorI7atuBEx7dUX06taNvJ+uOMsbUT12DwZs+i8qvtFcAf1HV90TkES+LSlDVfe7JcdfhdCsBjANy6xIKzVFIiNAtNpJusZGMr2V2VPXuqIWb9vPW8qq3KSayNX07VQWFdUcZYxrKm0+PnSLyAnAJ8ISItMG7RfgA3hKRWKAUuFtVD7vbpwBvePlczd6ZZkfV1h01c9kOTpY62S3izo7qZN1RxhjvedOVFIGzXtK3qrpJRDoD56nqZ74ssDbNrSupMdTWHbV+zzG2V+uOatMqhN41u6M6RxHfzrqjjGkJfNGVdBKIBG7EWRIjDDhSv/JMY/OmO2rBObqj+nVuT59O7Yhobd1RxrRELWqtpJaoLt1RubsLyd1be3dUWlIHrh3ShVG9460bypgWokWtlWSqxES25oKecVzQM+70turdUbm7C9mw9xhfbz7AB6t2kRDVhmuHdmVSRhK9EqICWLkxxtf8ulaSCW61dUeVlFUwd8M+ZucU8MrCbbwwfyvpyR2YlJnEVYO70D48LMBVG2MamzeDzzcBk4EM4O+4ayWp6iyfVXcGNvgcGPsLT/Heyp3Myi5gw95C2rQK4bJBiUzKSOaCnrGEhNgAtjHBrNFPcHOftB/OWkkAc7xcK6nRWDAElqry7c6jzMou4L2VOzlWXEaX6HCuz0hiYkYS3WIjA12iMaYWjRYMIvLA2far6tNe1tZgFgzBo7i0nC/W72VWdgELN+2nQiGrewyTMpK4/LzOdqKdMUGkMYPh1+7NvjgzkN53718FLFDVHzak0PqwYAhOe44W89byAmbnFLDtwAkiWody+XmdmZSRRFb3GDtXwpgA88VaSZ8B16tqoXs/Cpilqpc1qNJ6sGAIbqpKTt5hZmUX8OHqXZwoKadbbAQThyZxfUYSXTq0DXSJxrRIvgiGXGCwqp5y77cBVqlqvwZVWg8WDE1HUUkZn3y7h9k5BXyz9SAiMKJXHBMzkhg/MJHwsNBAl2hMi+GLM5//CSwVkXdwpqxeC/yjnvWZFiKidSuuz3BaCjsOFTE7x+lqunfGSqLCW3HV4C5MykgiPbmDdTUZEyS8nZU0FBjp3l2gqit8UtU5WIuhaauoUBZvPcisnAI+WbOb4tIKeiW0Y1JGEtcO7UpCVHigSzSmWWrMwWfRcxxUl2MakwVD81FYXMpHq3czK6eAnLzDhIYIY/rEMzEjibH9O9G6lS3DYUxjacxgmIezJtJ7qppfbXtrYARwKzBXVf/ekIK9YcHQPG3Zf5zZOQW8vbyAvcdO0TEijKvTuzIpM4mBXaLP/QTGmLNqzGAIB24HbgK646yo2hbnWgyfAc+p6soGV+wFC4bmrbxCWbBpP7NzCvh87V5KyisY0Lk9EzOSuGZIV2IibYkuY+rDV2c+hwFxONdqDtiS2xYMLceRohLeX7WLWdkFfLvzKGGhwth+nZiUmcToPrbiqzHe8EkwBAsLhpYpd88xZmUX8O6KnRw8UUJ8VBuuG+J0NdmKr8acmwWDabZKyyuYm7uPWTkFzM3dR1mFMji5A5MynBVfo9vaiq/G1MaCwbQIB46f4t0Vniu+jh+YyKTMJC7oGUeorfhqzGm+OPM5E1ivqicaWlxDWTCYms624uv1Q5NIjbMVX43xRTCsA4aqarF7Pw74nqp+2KBK68GCwZxNrSu+psYwMTOJK2zFV9OC+SIYlqvq0HNt8wcLBlNXZ1rxdWJGEsNtxVfTwvgiGGYDr6jqJ9W2rVHVQfUvs34sGIy3Kld8nZ1TwIerd3P8VBkpMRFMdNdx6morvpoWwBfB0Bn4BFgHLAYGAomqenVDCq0PCwbTEEUlZXy6Zg+zsqtWfL2wZxyTMm3FV9O8+WrwORcYD6QDe4C/B2Iw2oLBNJbqK77uPHKSqDatuHJwFyZlJjHEVnw1zUxQDj6LyL3AnYAAL6nqs+72e4D/A5QBH6nqz8/2PBYMprFVVCiLtx1kdnYBH1db8XViRhLXDelKQntb8dU0fUE3+Cwig4AZQBZQAnwK3AUkAQ8DV6jqKRFJUNV9Z3suCwbjS7Wt+Dq6TzyTMpK4uH8CbVpZV5NpmnxxoZ6tIvL96oPPgDermfUHFqtqkVvgfJyL/WQCj1deGe5coWCMr0WFhzElK4UpWSkeK77Oyd13esXXiRlJDOpqK76a5slvg88i0h94DzgfOAl8CWTjXPjnPeAyoBj4maouO9tzWYvB+Ft5hbJw035mVVvxtX/n9kzKSOLq9C7EtmsT6BKNOSdfra4aClxDPQefReQO4G7gOE7AnAQuAeYA9wLDgJlAj5oX/hGRacA0gJSUlIy8vLw6121MY6ptxdeL+yUwKSOZMX1txVcTvHwxxhAL3IDzrX4t8K2qnmxAgb8HCoAJOF1J89ztW3AGtfef6bHWYjDBInfPMWZnF/BOtRVfb8hMYsqwFJJjIgJdnjEefBEMC4AvcAaMN+J0CW1V1X5eFJWgqvtEJAXnIj/nA5OBLqr6KxHpg9PFlHK2S4VaMJhgU7ni68xlO5i7YR8KjOodz9ThKYztl2CtCBMUfDH4HKWqvxGR61R1tIhcD/Tysq633JZHKXC3qh4WkVeBV0VkDc5spVv9ef1oYxpDWGgIlw5M5NKBiew8cpKZy3Ywc1k+//nPHBLbh3PDsGSmDEumi51hbZoAb1oM36jq+SKyBBijqidFZL6qjvZtid9lLQbTFJSVV/Bl7j6mL8lnwab9CHBxvwSmDk9hdJ8EWxLc+J0vWgxPiUgMzuDwqyLyNdC1vgUa09y1CnWuDTF+YCI7DhXxxtJ83swu4Iv12XTt0JYpw5K5YVgynezkORNkvGkxdFPVPPf2zcB5wD9Uda0P66uVtRhMU1VSVsHn6/YyfWkeX20+SGiIMK5/AjcN78aIXnGEWCvC+JC/znz+nqourmeN9WbBYJqDbQdOMGNpPrNyCjh0ooSUmAimZCUzKSOZ+Cg7L8I0vkYLBhG5ARgKXI8ztXSjqpa7+1araloj1OsVCwbTnJwqK+fTNXuYviSfJdsOERYqXDowkZuyUji/Z6wt5GcaTWOOMXwFhAM/BJ4G+orIEWA3zglqxpgGaNMqlKvTu3J1elc27ytk+pIdvLW8gI9W76ZHXCQ3ZqVwfUYSMZHerEBjTP1505V0oap+5d6OAboDubbstjGNr7i0nI+/3c3rS/LJyTtM69AQvn9eIjcN78aw1I7WijD14osxhvnAVap6TER+hNOKeF5VSxpWqvcsGExLkrvnGG8syeft5TspPFVGr4R2TM1K4fqhSURHhAW6PNOE+CIYVqpquohkAC8CHwKpqnprw0r1ngWDaYmKSsr4cNVuXl+az6odR2jTKoQr07owdXgKQ1PsokLm3HxxHkOZiLQCbgGeUNU3RcQ+nY3xk4jWrbjBPfdhzc6jTF+az3srdvLW8gL6JUZx0/AUrh7Slfbh1oowDeNNi+EW4CGcLqRB7pnPud6sldRYrMVgjOP4qTLeX7mL15fksXbXMdqGhXJ1utOKSEvqEOjyTJDx1bLb7YByNxR6AQ+r6g8aUGe9WDAY40lVWV1wlOlL8nl/1S5OlpYzqGt7pmZ14+r0LkS28aZzwDRXPgmGYGHBYMyZHSsu5d0VO5m+JJ/cPYW0a9PqdCtiYBe76lxL5ovB597AL4GTqnp3A+trEAsGY85NVVmef5jXl+Tz0erdnCqrID25A1OHp3BVWhfatrZrV7c0vgiGxcCjOAPPaSIyCPi5qt7SsFK9Z8FgjHeOFJXw1vKdTF+Sx5b9J4gKb8V1Q7oydXg3+iZGBbo84ye+CIalqpolIitUdYi77TvrJ/mDBYMx9aOqLN12iNeX5PPpmj2UlFeQ2a0jN30vhe8P6kx4mLUimjNfTFfdJSLdAXVfQAC7dqExTYiIMLxHLMN7xHLoRAmzc3YwfUk+989cxaMfrOP6oUncmJVCr4R2gS7VBJA3LYZU4GVgAPAwcJn7+Bt8VdyZWIvBmMZTUaF8s/Ug05fk8++1eyirUL7XI4apw7sxfmAn2rSyVkRz4ZNlt4Es4FogDWcRvRWq+k1DCq0PCwZjfGNfYTGzsgt4Y2k+BYdPEhPZmkkZTisiNS4y0OWZBrJlt40x9VZRoSzcfIDXF+fxZe4+yiuUEb3imDo8hUsGdCIsNCTQJZp68Mey27uwZbeNaZZCQoTRfeIZ3SeePUeLeTN7BzOW5vPj15cTH9WGGzKTmDIsheQYG2ZsjmzZbWNMnZRXKPM27GP6knzmbtiHAqP7xDM1K4WL+yXQyloRQc/OfDbG+MzOIyeZuTSfGct2sK/wFIntw5k8LJkpWcl0jm4b6PLMGVgwGGN8rrS8gi/X72P60nwWbtqPABf3S2Dq8BRG90kgNMSWAg8mvjiPwRhjPISFhnDZoEQuG5TIjkNFvLE0nzezd/DF+n107dCWKcOSmTwsmYT24YEu1XjBWgzGmEZVUlbB5+v2Mn1pHl9tPkhoiHBJ/05MHZ7CiF5xhFgrImCsxWCMCYjWrUK4Iq0zV6R1ZtuBE7yxNJ9Z2Tv4dO0eUmIiuDErhUmZScS1axPoUs0Z+LXFICL3AncCArykqs+KyCPutv3uYf9XVT8+2/NYi8GYpuVUWTmfrtnD60vyWbrtEGGhwqUDE7lpeArn94i1y5L6SdANPrursc7AOXu6BPgUuAu4CTiuqk/V9bksGIxpujbvK2T6kh3MztnBseIyhqR04P5xfRjZO84CwsfqGgz+nHjcH1isqkWqWgbMx1lewxjTgvRKiOJXVw1g6cPj+N01g9hztJhbXl3KpL9+w6JNB2iK457NjT9bDP2B94Dzcc6Y/hLIBg4CtwHH3Ps/VdXDtTx+GjANICUlJSMvL88vdRtjfOtUWTlvLtvBc3O3sOdYMVmpMdx3SW8u6BkX6NKanaDrSgIQkTuAu4HjwDqcgHgcOICznPdvgc6qevvZnse6koxpfopLy5m5bAfPz9vM3mOnGN49hvsv6cP3esQGurRmIyiDweOFRX4PFKjq89W2pQIfquqgsz3WgsGY5qu4tJw3lubz/Lwt7C88xfk9Yrn/kj5kdY8JdGlNXjCOMSAiCe6fKcB1wBsi0rnaIdcCa/xZkzEmuISHhfKDC7uz8OcX8d9XDmDTvuPc8MI3/MfLS8jJOxTo8loEf3clLQRigVLgAVX9UkT+CaTjdCVtB/5TVXef7XmsxWBMy3GypJx/Lc7jr/O3cPBECSN7x3H/JX0YmtIx0KU1OUHfldQQFgzGtDxFJWX885s8XliwlUMnShjdJ577L+lDenKHQJfWZFgwGGOapROnynjtmzxeXLCFw0WlXNwvgfvG9SYtyQLiXCwYjDHN2vFTZfzj6+28uGArR0+WMq5/AveN68OgrtGBLi1oWTAYY1qEwuJS/v7Vdl5auJVjxWVcMqAT943rzcAuFhA1tbhgKC0tpaCggOLi4gBVFXzCw8NJSkoiLCws0KUY43PHikv526LtvLxoK4XFZYwf2In7xvWhf+f2gS4taLS4YNi2bRtRUVHExtqCXACqysGDByksLKR79+6BLscYvzl6spRXFm3jb4u2UXiqjMvPS+TesX3omxgV6NICLijPY/Cl4uJiC4VqRITY2FhrQZkWJ7ptGA9c0odFD13MPRf3YsHGA1z2pwXcPX05m/YWBrq8JqHZBANgoVCDvR+mJYuOCOOnl/Zl4c8v4sdjejIvdx+XPruAe95YweZ9FhBn06yCIZg88sgjPPVUnVcSN8b4SMfI1jw4vh8LH7qYH43uyZfr93LJMwu4b8YKtu4/HujygpIFgzGmRYiJbM1Dl/Vj4c8vYtrIHvx77V7GPT2fB2auZNuBE4EuL6hYMDSixx57jL59+zJu3Dg2bNgAwJZee8rEAAAQ5UlEQVQtW7jsssvIyMhg5MiR5ObmAnDbbbfxk5/8hAsuuIAePXowe/ZsAHbv3s2oUaNIT09n0KBBLFy4EIC77rqLzMxMBg4cyK9//evA/ILGNAOx7drwy8v7s/Chi7hjRHc+XrObcU/P56dvriLvoAUENNNrPj/6wVrW7TrWqM85oEt7fn3VwDPuz8nJYcaMGaxYsYKysjKGDh1KRkYG06ZN469//Su9e/dmyZIl/PjHP2bOnDmAEwKLFi0iNzeXCRMmMHHiRKZPn8748eN5+OGHKS8vp6ioCHBCJyYmhvLycsaOHcvq1atJS0tr1N/RmJYkrl0bHr5iAHeO6sEL87fyr8V5vLtyJ9cP7co9F/cmOSYi0CUGTLMMhkBYuHAh1157LRERzj+mCRMmUFxczNdff82kSZNOH3fq1KnTt6+55hpCQkIYMGAAe/fuBWDYsGHcfvvtlJaWcs0115Ceng7Am2++yYsvvkhZWRm7d+9m3bp1FgzGNIKEqHD++8oB/OeoHvxl/hZeX5LP28t3MjEjibsv6tUiA6JZBsPZvtn7Us1ZQBUVFXTo0IGVK1fWenybNm1O3648n2TUqFEsWLCAjz76iJtvvpkHH3yQkSNH8tRTT7Fs2TI6duzIbbfdZtNQjWlkCe3D+fVVA/nR6J78Zd4Wpi/JZ3ZOAZMyk/k/F/eia4e2gS7Rb2yMoZGMGjWKd955h5MnT1JYWMgHH3xAREQE3bt3Z9asWYDz4b9q1aqzPk9eXh4JCQnceeed3HHHHSxfvpxjx44RGRlJdHQ0e/fu5ZNPPvHHr2RMi9SpfTiPTBjI/J+P4casFN7KKWDMk3N5+J1v2XXkZKDL84tm2WIIhKFDhzJ58mTS09Pp1q0bI0eOBOD111/nrrvu4ne/+x2lpaVMmTKFwYMHn/F55s2bx5NPPklYWBjt2rXjtddeo3v37gwZMoSBAwfSo0cPLrzwQn/9Wsa0WJ2j2/LbawZx15iePDd3M29m72BWdgFTspL58ZheJEaHB7pEn2k2S2KsX7+e/v37B6ii4GXvizGNo+BwEc/N3cKs7B2EhAhTs1K4a0xPOrVvOgHR4pbEMMYYX0rqGMEfrjuPuT8bw3VDuvLPxXmM+uNcHv1gLfsKm9eYnwWDMcZ4ITkmgsevT2PuT8cwYXAXXvsmj5FPzOW3H65jf+Gpcz9BE2DBYIwx9ZASG8GTkwbz5QOjuTKtC3/7ahsj/ziH33+8ngPHm3ZAWDAYY0wDpMZF8j83DObLn47h8kGdeXnhVkY+MZc/fLKeQydKAl1evVgwGGNMI+geF8nTk9P5/IHRjB/YiRcXbGXEE3N44tNcDjexgLBgMMaYRtQzvh3PThnC5/ePYmz/Tvx1/hZGPDGHJ/+dy5GiphEQFgxN2Pbt25k+fXqgyzDG1KJXQhT/e+MQ/n3fKMb0S+C5uVsY8cRcnv5sA0eLSgNd3llZMDRhFgzGBL8+naJ4bupQ/n3fKEb1iePPczYz4o9zeObzjRw9GZwBYcHQiF577TXS0tIYPHgwN998M3l5eYwdO5a0tDTGjh1Lfn4+R48eJTU1lYqKCgCKiopITk6mtLSUMWPG8NBDD5GVlUWfPn1OL7ldXl7Ogw8+yLBhw0hLS+OFF14A4Be/+AULFy4kPT2dZ555JmC/tzHm3PomRvH8TRl8cu9ILugZy5++3MTIJ+bw5y83UVgcXAHh1yUxRORe4E5AgJdU9dlq+34GPAnEq+qBBr3QJ7+APd826Cm+I/E8+P7jZ9y9du1aHnvsMb766ivi4uI4dOgQt956K7fccgu33norr776Kj/5yU949913GTx4MPPnz+eiiy7igw8+YPz48YSFhQFQVlbG0qVL+fjjj3n00Uf54osveOWVV4iOjmbZsmWcOnWKCy+8kEsvvZTHH3+cp556ig8//LBxf1djjM/079yeF27OZO2uozz7xSae/nwjryzaxp0ju3Pbhd1p1ybwKxX5rcUgIoNwQiELGAxcKSK93X3JwCVAvr/qaWxz5sxh4sSJxMXFARATE8M333zD1KlTAbj55ptZtGgRAJMnT2bmzJkAzJgxg8mTJ59+nuuuuw6AjIwMtm/fDsBnn33Ga6+9Rnp6OsOHD+fgwYNs2rTJX7+aMcYHBnaJ5qVbMvnwnhEMS+3IU59tZMQTc3hu7maOnyoLaG3+jKb+wGJVLQIQkfnAtcAfgWeAnwPvNcorneWbva+o6neW3a6pcv+ECRP45S9/yaFDh8jJyeHiiy8+fUzlUtyhoaGUlZWdfu7//d//Zfz48R7PN2/evEb8DYwxgTCoazQv3zqM1QVHePaLTTz57w28vHAr00b15JbzuxEZgBaEP8cY1gCjRCRWRCKAy4FkEZkA7FTVs69HHeTGjh3Lm2++ycGDBwE4dOgQF1xwATNmzACcVVZHjBgBQLt27cjKyuLee+/lyiuvJDQ09KzPPX78eP7yl79QWur0Q27cuJETJ04QFRVFYWGhD38rY4y/pCV14NXbhvHu3RcyOLkDT3yay6g/zuXFBVsoKvFvC8JvUaSq60XkCeBz4DiwCigDHgYuPdfjRWQaMA0gJSXFh5XWz8CBA3n44YcZPXo0oaGhDBkyhD//+c/cfvvtPPnkk8THx/O3v/3t9PGTJ09m0qRJdfrW/8Mf/pDt27czdOhQVJX4+Hjeffdd0tLSaNWqFYMHD+a2227j/vvv9+FvaIzxh/TkDvz9B1kszz/MM59v5Pcf5/Ligq38aHRPbhrejbatz/5FsjEEbNltEfk9sBcnGIrczUnALiBLVfec6bG27Hbd2ftiTNOWk3eIZz7fxKLNB4iPasOfpqRzQc+4ej1XXZfd9vespARV3SciKcB1wPmq+qdq+7cDmQ2elWSMMc1ERrcY/vXD4Szbfoj/N2cz3eMiff6a/h7VeEtEYoFS4G5VPezn1zfGmCZpWGoM/7g9yy+v5ddgUNWR59if6qdSjDHGnEGzOvO5KV6m1Jfs/TDG1EezCYbw8HAOHjxoH4YuVeXgwYOEhzed69EaY4JD4M+9biRJSUkUFBSwf//+QJcSNMLDw0lKSgp0GcaYJqbZBENYWBjdu3cPdBnGGNPkNZuuJGOMMY3DgsEYY4wHCwZjjDEeArYkRkOIyH4gr54PjwOC8cxqq8s7Vpd3rC7vBGtd0LDauqlq/LkOapLB0BAikl2XtUL8zeryjtXlHavLO8FaF/inNutKMsYY48GCwRhjjIeWGAwvBrqAM7C6vGN1ecfq8k6w1gV+qK3FjTEYY4w5u5bYYjDGGHMWzTYYROQyEdkgIptF5Be17G8jIjPd/UtEJDVI6holIstFpExEJvqjpjrW9YCIrBOR1SLypYh0C5K6fiQi34rIShFZJCIDgqGuasdNFBEVEb/McKnD+3WbiOx336+VIvLDYKjLPeYG99/YWhGZHgx1icgz1d6rjSJyJEjqShGRuSKywv0/eXmjFqCqze4HCAW2AD2A1jjXlx5Q45gfA391b08BZgZJXalAGvAaMDGI3q+LgAj39l1B9H61r3Z7AvBpMNTlHhcFLAAW41yZMOB1AbcB/88f/668rKs3sALo6N5PCIa6ahx/D/BqMNSFM85wl3t7ALC9MWtori2GLGCzqm5V1RJgBnB1jWOuBv7h3p4NjBURCXRdqrpdVVcDFT6uxdu65qpq5bW5F+NcnzsY6jpW7W4k4I9Bs7r8+wL4LfBHoNgPNXlTl7/Vpa47gefUvaqjqu4LkrqquxF4I0jqUqC9ezsa2NWYBTTXYOgK7Kh2v8DdVusxqloGHAVig6CuQPC2rjuAT3xakaNOdYnI3SKyBedD+CfBUJeIDAGSVfVDP9RT57pc17vdD7NFJDlI6uoD9BGRr0RksYhcFiR1AeB2nXYH5gRJXY8A/yEiBcDHOK2ZRtNcg6G2b/41v0nW5ZjGFojXrIs61yUi/wFkAk/6tCL35WrZ9p26VPU5Ve0JPAT8l8+rOkddIhICPAP81A+1VFeX9+sDIFVV04AvqGo1+1Jd6mqF0500Bueb+csi0iEI6qo0BZitquU+rKdSXeq6Efi7qiYBlwP/dP/dNYrmGgwFQPVvQkl8t6l1+hgRaYXTHDsUBHUFQp3qEpFxwMPABFU9FSx1VTMDuManFTnOVVcUMAiYJyLbge8B7/thAPqc75eqHqz2d/cSkOHjmupUl3vMe6paqqrbgA04QRHouipNwT/dSFC3uu4A3gRQ1W+AcJw1lBqHrwdSAvGD8+1jK07Tr3LwZmCNY+7Gc/D5zWCoq9qxf8d/g891eb+G4AyI9Q6yv8fe1W5fBWQHQ101jp+Hfwaf6/J+da52+1pgcZDUdRnwD/d2HE5XSmyg63KP6wtsxz3vK0jer0+A29zb/XGCo9Hq8/kvGagfnObVRvfD7GF3229wvu2Ck7CzgM3AUqBHkNQ1DOcbwwngILA2SOr6AtgLrHR/3g+Suv4ErHVrmnu2D2h/1lXjWL8EQx3frz+479cq9/3qFyR1CfA0sA74FpgSDHW59x8BHvdHPV68XwOAr9y/x5XApY35+nbmszHGGA/NdYzBGGNMPVkwGGOM8WDBYIwxxoMFgzHGGA8WDMYYYzxYMBhjjPFgwWCMMcaDBYNp9kSkrYjMF5FQLx/39Rm2PyIiP2uc6nxDRFqLyAJ3uRdjvGLBYFqC24G3tcYCaOI44/8BVb3A55X5iDrLNX8JTA50LabpsWAwTZqIDHa/Ga8TkQr3ammP1jjsJuA99/hUEVkvIs8Dy4GRIrKm2vP9TEQecW8fr7b9YfeKWl/grJ1Tuf0BEVnj/tx3ljr/W0RyReRzEXmjssUhIu+KSI571bJp1Wo8U02RIvKRiKxyX3Nybdvch77r/u7GeMWamabJEpFwYCZwi6ouFZHf4qyB9Ui1Y1rjrIO1vdpD+wI/UNUfSx0u6SoiGTgLLQ7B+T+zHMhxt/8AGI6z1s8SEZmvqitqPD4TuL7m493dt6vqIRFpCywTkbfOUc5lwC5VvcJ97ugzbANYg7P2ljFesRaDacrGActVdal7fzUQo54LgMUBNa/Tm6eqi714nZHAO6papM4V4953t49wt59Q1ePA2+6xNY3AWVL6pKoW4lwTodJPRGQVzlXxkjn3UtPfAuNE5AkRGamqR8+wDbfrrEREorz4XY2xYDBN2iCcD8VKQ3G+jVd3EqcVUd2JarfL8Px/UPPYSrWtNlnXS8HWepyIjMEJt/NVdTDONY/Dz1aTqm7EuYbCt8AfRORXtW2r9tg2+O/SoqaZsGAwTdlBIA1ARPoA1+FcrOc0da4hHOp2O9VmL5AgIrEi0ga4spZjFgDXurObonCu+1C5/RoRiRCRSJzrGyys5fGLgKtEJFxE2gFXuNujgcOqWiQi/XAu6HPWmkSkC1Ckqv8CngKG1rbNPTYW2K+qpWf43Y2plY0xmKbsDWCCO1B7ALhRVQ/WctxnON05X9TcoaqlIvIbYAmwDcit5ZjlIjITZ937PNwPf3f733Gu5wHwcs3xBfe4ZSLyPs7a+XlANs41xj8FfiQiq3GuWLa4DjWdBzwpIhVAKXDXGbYBXIRzPWBjvGLXYzDNnogMAR5Q1ZsDWEM7VT0uIhE4LY1pqlqz26uxX/Nt4JequsGXr2OaH2sxmGZPVVeIyFwRCa15LoMfvSgiA3DGC/7hh1BoDbxroWDqw1oMxhhjPNjgszHGGA8WDMYYYzxYMBhjjPFgwWCMMcaDBYMxxhgPFgzGGGM8WDAYY4zxYMFgjDHGw/8Hlsvl71nzI+IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como podemos observar de la grafica, el desempeño de la red densa se ve altamente afectado por el ruido aplicado a los datos de entrenamiento. Por el otro caso, la red convolucional ni siquiera se pudo sentir el ruido aplicado a las imagenes de los datos por lo que es mas robusta. Concluimos que para el tratamiento de redes neuronales con datos de imagenes, es mejor aplicar redes convolucionales, debido a que pueden filtar este tipo de patrones con mejor eficacia que las redes densas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}